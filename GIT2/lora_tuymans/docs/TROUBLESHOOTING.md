# ğŸ› Troubleshooting Guide

## PÅ™ehled

KomplexnÃ­ guide pro Å™eÅ¡enÃ­ problÃ©mÅ¯ s aplikacÃ­ LoRA Tuymans Style Transfer.

## ğŸ“‹ Obsah

- [ğŸš¨ KritickÃ© chyby](#-kritickÃ©-chyby)
- [âš¡ VÃ½konnostnÃ­ problÃ©my](#-vÃ½konnostnÃ­-problÃ©my)
- [ğŸ–¥ï¸ GPU problÃ©my](#ï¸-gpu-problÃ©my)
- [ğŸ³ Docker problÃ©my](#-docker-problÃ©my)
- [ğŸŒ SÃ­Å¥ovÃ© problÃ©my](#-sÃ­Å¥ovÃ©-problÃ©my)
- [ğŸ“ ProblÃ©my s modely](#-problÃ©my-s-modely)
- [ğŸ”§ DiagnostickÃ© nÃ¡stroje](#-diagnostickÃ©-nÃ¡stroje)
- [ğŸ“ ZÃ­skÃ¡nÃ­ podpory](#-zÃ­skÃ¡nÃ­-podpory)

---

## ğŸš¨ KritickÃ© chyby

### "CUDA out of memory"

**PÅ™Ã­znaky:**
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**PÅ™Ã­Äiny:**
- Nedostatek VRAM
- PÅ™Ã­liÅ¡ velkÃ½ batch size
- Memory leak
- JinÃ© procesy pouÅ¾Ã­vajÃ­ GPU

**Å˜eÅ¡enÃ­:**

#### 1. OkamÅ¾itÃ© Å™eÅ¡enÃ­
```bash
# Restart aplikace
docker restart lora_tuymans
# nebo
Ctrl+C a znovu spustit
```

#### 2. Optimalizace pamÄ›ti
```bash
# Environment variables
export ENABLE_ATTENTION_SLICING=true
export ENABLE_CPU_OFFLOAD=true
export MAX_MEMORY_GB=6
```

#### 3. SnÃ­Å¾enÃ­ parametrÅ¯
- Batch Count: 3 â†’ 1
- Upscaling: Vypnout
- Steps: 30 â†’ 20

#### 4. VyÄiÅ¡tÄ›nÃ­ GPU pamÄ›ti
```python
# V Python konzoli
import torch
torch.cuda.empty_cache()
```

#### 5. Kontrola jinÃ½ch procesÅ¯
```bash
# Zobrazit GPU procesy
nvidia-smi

# UkonÄit jinÃ© procesy
sudo kill -9 PID
```

### "ModuleNotFoundError"

**PÅ™Ã­znaky:**
```
ModuleNotFoundError: No module named 'torch'
ModuleNotFoundError: No module named 'diffusers'
```

**Å˜eÅ¡enÃ­:**

#### 1. Kontrola virtual environment
```bash
# Aktivace venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Kontrola aktivace
which python
which pip
```

#### 2. Reinstalace dependencies
```bash
# Upgrade pip
pip install --upgrade pip

# Reinstalace
pip install --force-reinstall -r requirements.txt

# Nebo jednotlivÄ›
pip install torch torchvision torchaudio
pip install diffusers transformers
pip install streamlit
```

#### 3. Kontrola Python verze
```bash
# MinimÃ¡lnÃ­ verze: 3.10
python --version

# Pokud je starÅ¡Ã­
sudo apt install python3.11
python3.11 -m venv venv
```

### "Permission denied"

**PÅ™Ã­znaky:**
```
PermissionError: [Errno 13] Permission denied: '/data/loras'
FileNotFoundError: [Errno 2] No such file or directory
```

**Å˜eÅ¡enÃ­:**

#### 1. OprÃ¡vnÄ›nÃ­ sloÅ¾ek
```bash
# VytvoÅ™enÃ­ sloÅ¾ek
mkdir -p data/loras data/models

# NastavenÃ­ oprÃ¡vnÄ›nÃ­
chmod 755 data/
chmod 755 data/loras/
chmod 755 data/models/

# VlastnictvÃ­
sudo chown -R $USER:$USER data/
```

#### 2. Docker oprÃ¡vnÄ›nÃ­
```bash
# PÅ™idÃ¡nÃ­ uÅ¾ivatele do docker skupiny
sudo usermod -aG docker $USER

# Restart session
newgrp docker
```

#### 3. SELinux/AppArmor
```bash
# Kontrola SELinux
getenforce

# DoÄasnÃ© vypnutÃ­
sudo setenforce 0

# TrvalÃ© vypnutÃ­
sudo nano /etc/selinux/config
# SELINUX=disabled
```

---

## âš¡ VÃ½konnostnÃ­ problÃ©my

### PomalÃ© generovÃ¡nÃ­

**Diagnostika:**
```bash
# Monitoring GPU
watch -n 1 nvidia-smi

# Monitoring CPU
htop

# Monitoring pamÄ›ti
free -h
```

**Optimalizace:**

#### 1. GPU optimalizace
```bash
# Persistence mode
sudo nvidia-smi -pm 1

# Performance mode
sudo nvidia-smi -ac 877,1215

# Power limit (podle GPU)
sudo nvidia-smi -pl 300
```

#### 2. System optimalizace
```bash
# CPU governor
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# Swappiness
echo 'vm.swappiness=10' | sudo tee -a /etc/sysctl.conf

# Cache pressure
echo 'vm.vfs_cache_pressure=50' | sudo tee -a /etc/sysctl.conf
```

#### 3. AplikaÄnÃ­ optimalizace
```bash
# Environment variables
ENABLE_ATTENTION_SLICING=true
ENABLE_CPU_OFFLOAD=false  # Pokud mÃ¡te dostatek VRAM
MAX_MEMORY_GB=16
```

### VysokÃ© vyuÅ¾itÃ­ RAM

**Monitoring:**
```bash
# Continuous monitoring
watch -n 1 'free -h && ps aux --sort=-%mem | head -10'

# Memory map
sudo pmap -x $(pgrep python)
```

**Å˜eÅ¡enÃ­:**

#### 1. Memory cleanup
```bash
# Clear cache
sudo sync && sudo echo 3 > /proc/sys/vm/drop_caches

# Docker cleanup
docker system prune -f
docker volume prune -f
```

#### 2. AplikaÄnÃ­ optimalizace
```python
# V kÃ³du - garbage collection
import gc
gc.collect()

# CUDA cache cleanup
import torch
torch.cuda.empty_cache()
```

---

## ğŸ–¥ï¸ GPU problÃ©my

### GPU nenÃ­ detekovÃ¡na

**Diagnostika:**
```bash
# ZÃ¡kladnÃ­ kontrola
nvidia-smi
lspci | grep -i nvidia

# CUDA kontrola
nvcc --version
python -c "import torch; print(torch.cuda.is_available())"
```

**Å˜eÅ¡enÃ­:**

#### 1. Driver problÃ©my
```bash
# Kontrola verze
nvidia-smi

# Reinstalace (Ubuntu)
sudo apt purge nvidia-*
sudo apt autoremove
sudo apt install nvidia-driver-535
sudo reboot
```

#### 2. CUDA toolkit
```bash
# Instalace CUDA 12.1
wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run
sudo sh cuda_12.1.1_530.30.02_linux.run

# Environment
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

#### 3. Docker GPU support
```bash
# NVIDIA Docker
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update && sudo apt install -y nvidia-docker2
sudo systemctl restart docker

# Test
docker run --rm --gpus all nvidia/cuda:12.1.1-base-ubuntu22.04 nvidia-smi
```

### GPU pÅ™ehÅ™Ã­vÃ¡nÃ­

**Monitoring:**
```bash
# Teplota
watch -n 1 'nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits'

# Fan speed
nvidia-smi --query-gpu=fan.speed --format=csv,noheader,nounits
```

**Å˜eÅ¡enÃ­:**

#### 1. Fan curve
```bash
# Manual fan control
sudo nvidia-smi -pm 1
sudo nvidia-settings -a "[gpu:0]/GPUFanControlState=1"
sudo nvidia-settings -a "[fan:0]/GPUTargetFanSpeed=80"
```

#### 2. Power limiting
```bash
# SnÃ­Å¾enÃ­ power limitu
sudo nvidia-smi -pl 250  # Z 300W na 250W
```

#### 3. Undervolting
```bash
# PomocÃ­ MSI Afterburner nebo nvidia-settings
# SnÃ­Å¾enÃ­ core voltage o 50-100mV
```

---

## ğŸ³ Docker problÃ©my

### Container se nespustÃ­

**Diagnostika:**
```bash
# Logs
docker logs lora_tuymans

# Inspect
docker inspect lora_tuymans

# Events
docker events --filter container=lora_tuymans
```

**ÄŒastÃ© chyby:**

#### 1. Port jiÅ¾ pouÅ¾Ã­vÃ¡n
```bash
# NajÃ­t proces
sudo netstat -tulpn | grep 8501
sudo lsof -i :8501

# UkonÄit
sudo kill -9 PID

# Nebo pouÅ¾Ã­t jinÃ½ port
docker run -p 8502:8501 ...
```

#### 2. Volume problÃ©my
```bash
# Kontrola cest
ls -la $(pwd)/data

# OprÃ¡vnÄ›nÃ­
sudo chown -R 1000:1000 data/

# SELinux context
sudo chcon -Rt svirt_sandbox_file_t data/
```

#### 3. GPU access
```bash
# Test GPU v containeru
docker run --rm --gpus all nvidia/cuda:12.1.1-base-ubuntu22.04 nvidia-smi

# Pokud nefunguje
sudo systemctl restart nvidia-docker
sudo systemctl restart docker
```

### Image build problÃ©my

**ÄŒastÃ© chyby:**

#### 1. Network timeout
```bash
# Proxy nastavenÃ­
docker build --build-arg HTTP_PROXY=http://proxy:8080 .

# DNS
echo '{"dns": ["8.8.8.8", "8.8.4.4"]}' | sudo tee /etc/docker/daemon.json
sudo systemctl restart docker
```

#### 2. Disk space
```bash
# Cleanup
docker system prune -a
docker volume prune

# Kontrola mÃ­sta
df -h
docker system df
```

#### 3. Memory limit
```bash
# ZvÃ½Å¡enÃ­ build memory
docker build --memory=8g .

# Nebo v daemon.json
{
  "default-ulimits": {
    "memlock": {
      "Hard": -1,
      "Name": "memlock",
      "Soft": -1
    }
  }
}
```

---

## ğŸŒ SÃ­Å¥ovÃ© problÃ©my

### Aplikace nenÃ­ dostupnÃ¡

**Diagnostika:**
```bash
# Port listening
sudo netstat -tulpn | grep 8501

# Firewall
sudo ufw status
sudo iptables -L

# Connectivity
curl -I http://localhost:8501
telnet localhost 8501
```

**Å˜eÅ¡enÃ­:**

#### 1. Firewall konfigurace
```bash
# UFW
sudo ufw allow 8501/tcp

# iptables
sudo iptables -A INPUT -p tcp --dport 8501 -j ACCEPT
sudo iptables-save > /etc/iptables/rules.v4
```

#### 2. Streamlit konfigurace
```toml
# .streamlit/config.toml
[server]
address = "0.0.0.0"  # Ne 127.0.0.1
port = 8501
enableCORS = true
```

#### 3. Cloud provider security groups
```bash
# AWS Security Group
# Inbound: TCP 8501 from 0.0.0.0/0

# GCP Firewall
gcloud compute firewall-rules create allow-streamlit \
  --allow tcp:8501 \
  --source-ranges 0.0.0.0/0
```

### PomalÃ© stahovÃ¡nÃ­ modelÅ¯

**Diagnostika:**
```bash
# Rychlost pÅ™ipojenÃ­
speedtest-cli

# DNS
nslookup huggingface.co

# Traceroute
traceroute huggingface.co
```

**Optimalizace:**

#### 1. Mirror/CDN
```bash
# HuggingFace mirror
export HF_ENDPOINT=https://hf-mirror.com

# Nebo lokÃ¡lnÃ­ cache
export HF_HOME=/fast/cache/huggingface
```

#### 2. Parallel downloads
```python
# V kÃ³du
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id="model_name",
    max_workers=8,
    resume_download=True
)
```

---

## ğŸ“ ProblÃ©my s modely

### Model se nenaÄte

**Diagnostika:**
```bash
# Kontrola souboru
file model.safetensors
ls -la model.safetensors

# Integrita
sha256sum model.safetensors

# Obsah
python -c "from safetensors import safe_open; print(list(safe_open('model.safetensors', framework='pt').keys())[:10])"
```

**ÄŒastÃ© problÃ©my:**

#### 1. PoÅ¡kozenÃ½ soubor
```bash
# Re-download
wget -c -O model.safetensors "MODEL_URL"

# Nebo z backup
cp backup/model.safetensors data/loras/
```

#### 2. NekompatibilnÃ­ formÃ¡t
```python
# Konverze z .ckpt
from diffusers import StableDiffusionPipeline
pipe = StableDiffusionPipeline.from_ckpt("model.ckpt")
pipe.save_pretrained("converted_model", safe_serialization=True)
```

#### 3. Å patnÃ¡ cesta
```bash
# Kontrola struktury
tree data/

# SprÃ¡vnÃ© umÃ­stÄ›nÃ­
# LoRA: data/loras/model.safetensors
# Full: data/models/model.safetensors
```

### Å patnÃ© vÃ½sledky

**Diagnostika:**
- Zkontrolujte typ modelu (LoRA vs Full)
- OvÄ›Å™te kompatibilitu s base modelem
- Testujte s rÅ¯znÃ½mi parametry

**Å˜eÅ¡enÃ­:**

#### 1. Model compatibility
```python
# Kontrola base modelu
print(f"Base model: {BASE_MODEL}")
print(f"LoRA model: {model_path}")

# KompatibilnÃ­ kombinace:
# SDXL base + SDXL LoRA
# SD 1.5 base + SD 1.5 LoRA
```

#### 2. Parameter tuning
```python
# Pro LoRA modely
strength = 0.6-0.8
cfg_scale = 7-9

# Pro Full modely
strength = 0.7-0.9
cfg_scale = 6-8
```

---

## ğŸ”§ DiagnostickÃ© nÃ¡stroje

### System Information Script

```bash
#!/bin/bash
# system_info.sh

echo "=== SYSTEM INFORMATION ==="
echo "OS: $(lsb_release -d | cut -f2)"
echo "Kernel: $(uname -r)"
echo "CPU: $(lscpu | grep 'Model name' | cut -d':' -f2 | xargs)"
echo "RAM: $(free -h | grep Mem | awk '{print $2}')"
echo "Disk: $(df -h / | tail -1 | awk '{print $4}') free"

echo "\n=== GPU INFORMATION ==="nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader

echo "\n=== DOCKER INFORMATION ==="
docker --version
docker info | grep -E "Server Version|Storage Driver|Logging Driver"

echo "\n=== PYTHON ENVIRONMENT ==="
python --version
pip list | grep -E "torch|diffusers|streamlit"

echo "\n=== APPLICATION STATUS ==="
curl -s http://localhost:8501/_stcore/health && echo "âœ… App: OK" || echo "âŒ App: FAILED"

echo "\n=== DISK USAGE ==="
du -sh data/loras/ data/models/ 2>/dev/null || echo "Model directories not found"
```

### Performance Monitor

```bash
#!/bin/bash
# monitor.sh

while true; do
    clear
    echo "=== $(date) ==="
    
    echo "\nğŸ–¥ï¸  CPU:"
    top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1
    
    echo "\nğŸ’¾ RAM:"
    free -h | grep Mem | awk '{printf "Used: %s / %s (%.1f%%)\n", $3, $2, $3/$2*100}'
    
    echo "\nğŸ® GPU:"
    nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits | \
    awk -F, '{printf "GPU: %s%% | VRAM: %s/%s MB | Temp: %sÂ°C\n", $1, $2, $3, $4}'
    
    echo "\nğŸ³ Docker:"
    docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" | head -2
    
    sleep 5
done
```

### Health Check Script

```bash
#!/bin/bash
# health_check.sh

ERRORS=0

# Application health
if curl -f http://localhost:8501/_stcore/health > /dev/null 2>&1; then
    echo "âœ… Application: OK"
else
    echo "âŒ Application: FAILED"
    ((ERRORS++))
fi

# GPU health
if nvidia-smi > /dev/null 2>&1; then
    TEMP=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
    if [ $TEMP -lt 85 ]; then
        echo "âœ… GPU: OK (${TEMP}Â°C)"
    else
        echo "âš ï¸  GPU: HOT (${TEMP}Â°C)"
        ((ERRORS++))
    fi
else
    echo "âŒ GPU: FAILED"
    ((ERRORS++))
fi

# Memory health
MEM_USAGE=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100.0}')
if [ $MEM_USAGE -lt 90 ]; then
    echo "âœ… Memory: OK (${MEM_USAGE}%)"
else
    echo "âš ï¸  Memory: HIGH (${MEM_USAGE}%)"
    ((ERRORS++))
fi

# Disk health
DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
if [ $DISK_USAGE -lt 85 ]; then
    echo "âœ… Disk: OK (${DISK_USAGE}%)"
else
    echo "âš ï¸  Disk: HIGH (${DISK_USAGE}%)"
    ((ERRORS++))
fi

# Model directories
if [ -d "data/loras" ] && [ -d "data/models" ]; then
    LORA_COUNT=$(find data/loras -name "*.safetensors" | wc -l)
    MODEL_COUNT=$(find data/models -name "*.safetensors" | wc -l)
    echo "âœ… Models: ${LORA_COUNT} LoRA, ${MODEL_COUNT} Full"
else
    echo "âŒ Model directories missing"
    ((ERRORS++))
fi

echo "\n=== SUMMARY ==="
if [ $ERRORS -eq 0 ]; then
    echo "ğŸ‰ All systems operational!"
    exit 0
else
    echo "âš ï¸  Found $ERRORS issues"
    exit 1
fi
```

---

## ğŸ“ ZÃ­skÃ¡nÃ­ podpory

### PÅ™ed kontaktovÃ¡nÃ­m podpory

1. **SpusÅ¥te diagnostiku:**
   ```bash
   ./system_info.sh > system_report.txt
   ./health_check.sh >> system_report.txt
   ```

2. **ShromÃ¡Å¾dÄ›te logy:**
   ```bash
   # Application logs
   docker logs lora_tuymans > app_logs.txt 2>&1
   
   # System logs
   journalctl -u docker > system_logs.txt
   
   # GPU logs
   nvidia-smi -q > gpu_info.txt
   ```

3. **PÅ™ipravte informace:**
   - Verze aplikace
   - OperaÄnÃ­ systÃ©m
   - Hardware specifikace
   - Kroky k reprodukci problÃ©mu
   - ChybovÃ© hlÃ¡Å¡ky

### KontaktnÃ­ informace

**ğŸ› GitHub Issues:**
- URL: https://github.com/your-username/lora_tuymans/issues
- Template: Bug report, Feature request
- PÅ™iloÅ¾te: system_report.txt, logy

**ğŸ’¬ GitHub Discussions:**
- URL: https://github.com/your-username/lora_tuymans/discussions
- Kategorie: Q&A, General, Ideas

**ğŸ“§ Email podpora:**
- Email: your-email@example.com
- PÅ™edmÄ›t: "[LoRA Tuymans] Popis problÃ©mu"
- PÅ™iloÅ¾te: diagnostickÃ© soubory

**ğŸ“± Community:**
- Discord: [Server link]
- Reddit: r/StableDiffusion
- Stack Overflow: tag "lora-tuymans"

### Template pro hlÃ¡Å¡enÃ­ chyb

```markdown
## ğŸ› Bug Report

**Popis problÃ©mu:**
StruÄnÃ½ popis toho, co se dÄ›je.

**Kroky k reprodukci:**
1. Krok 1
2. Krok 2
3. Krok 3

**OÄekÃ¡vanÃ© chovÃ¡nÃ­:**
Co by se mÄ›lo stÃ¡t.

**SkuteÄnÃ© chovÃ¡nÃ­:**
Co se skuteÄnÄ› stalo.

**ProstÅ™edÃ­:**
- OS: [Ubuntu 22.04]
- GPU: [RTX 4090]
- Docker: [Yes/No]
- Verze: [v2.0.0]

**Logy:**
```
VloÅ¾te relevantnÃ­ logy zde
```

**Screenshots:**
PÅ™iloÅ¾te screenshots pokud je to relevantnÃ­.

**DodateÄnÃ© informace:**
JakÃ©koliv dalÅ¡Ã­ informace o problÃ©mu.
```

---

**ğŸ”§ Tento troubleshooting guide pokrÃ½vÃ¡ vÄ›tÅ¡inu bÄ›Å¾nÃ½ch problÃ©mÅ¯. Pokud vÃ¡Å¡ problÃ©m nenÃ­ uveden, nevÃ¡hejte kontaktovat podporu!**